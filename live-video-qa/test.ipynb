{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "audio_filename = \"interview_audio.wav\"\n",
    "\n",
    "recording_audio = False\n",
    "audio_stream = None\n",
    "recording_video = False\n",
    "\n",
    "def record_audio(duration=5, sample_rate=44100, channels=2):\n",
    "    global recording_audio, audio_stream\n",
    "\n",
    "    try:\n",
    "        audio_stream = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "status = record_audio(duration = 30)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import time\n",
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "audio_filename = \"interview_audio.wav\"\n",
    "\n",
    "recording_audio = False\n",
    "audio_stream = None\n",
    "recording_video = False\n",
    "\n",
    "def record_audio(duration=5, sample_rate=44100, channels=2):\n",
    "    global recording_audio, audio_stream\n",
    "\n",
    "    try:\n",
    "        audio_stream = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels)\n",
    "       \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return False\n",
    "\n",
    "def record(action):\n",
    "    global recording_audio, audio_stream\n",
    "    if action == 'start':\n",
    "        success = record_audio(duration=10)\n",
    "        if success:\n",
    "            recording_audio = True\n",
    "            time.sleep(5)\n",
    "            print(\"stopped button\")\n",
    "            # return jsonify({'status': 'started'})\n",
    "        else:\n",
    "            return jsonify({'status': 'error'})\n",
    "            \n",
    "    elif action == 'stop':\n",
    "        print(audio_stream)\n",
    "        print(\"in stop action\")\n",
    "        recording_audio = False\n",
    "        \n",
    "        if audio_stream is not None:\n",
    "            sd.wait()\n",
    "            write(audio_filename, 44100, audio_stream)\n",
    "            audio_stream = None\n",
    "        return jsonify({'status': 'stopped'})\n",
    "    else:\n",
    "        return jsonify({'status': 'unknown_action'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopped button\n",
      "[[-1.3122559e-03  9.1552734e-05]\n",
      " [-8.2397461e-04  9.7656250e-04]\n",
      " [-1.2207031e-03  2.7465820e-04]\n",
      " ...\n",
      " [-1.7669678e-02 -1.5411377e-02]\n",
      " [-2.5085449e-02 -1.4038086e-02]\n",
      " [-2.3315430e-02 -1.8615723e-02]]\n",
      "in stop action\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Working outside of application context.\n\nThis typically means that you attempted to use functionality that needed\nthe current application. To solve this, set up an application context\nwith app.app_context(). See the documentation for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m action\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     record(action)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     action\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb Cell 4\u001b[0m line \u001b[0;36mrecord\u001b[0;34m(action)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         write(audio_filename, \u001b[39m44100\u001b[39m, audio_stream)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         audio_stream \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m jsonify({\u001b[39m'\u001b[39;49m\u001b[39mstatus\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mstopped\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shivam/Documents/interview-analysis/face-emotion-recognition/live-video-qa/test.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m jsonify({\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39munknown_action\u001b[39m\u001b[39m'\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/flask/json/__init__.py:342\u001b[0m, in \u001b[0;36mjsonify\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjsonify\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response:\n\u001b[1;32m    311\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Serialize the given arguments as JSON, and return a\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m    :class:`~flask.Response` object with the ``application/json``\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    mimetype. A dict or list returned from a view will be converted to a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m    .. versionadded:: 0.2\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     \u001b[39mreturn\u001b[39;00m current_app\u001b[39m.\u001b[39;49mjson\u001b[39m.\u001b[39mresponse(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/werkzeug/local.py:316\u001b[0m, in \u001b[0;36m_ProxyLookup.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     obj \u001b[39m=\u001b[39m instance\u001b[39m.\u001b[39;49m_get_current_object()\n\u001b[1;32m    317\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfallback \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/werkzeug/local.py:513\u001b[0m, in \u001b[0;36mLocalProxy.__init__.<locals>._get_current_object\u001b[0;34m()\u001b[0m\n\u001b[1;32m    511\u001b[0m     obj \u001b[39m=\u001b[39m local\u001b[39m.\u001b[39mget()  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(unbound_message) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39mreturn\u001b[39;00m get_name(obj)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Working outside of application context.\n\nThis typically means that you attempted to use functionality that needed\nthe current application. To solve this, set up an application context\nwith app.app_context(). See the documentation for more information."
     ]
    }
   ],
   "source": [
    "action= 'start'\n",
    "while True:\n",
    "    record(action)\n",
    "    time.sleep(5)\n",
    "    action='stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
